/bin/true # puppet requires this for correct template parsing

# This is needed to pin a specific OSD id with a corresponding UUID.
# Problem is ceph-disk prepare doesn't accept ceph OSD id as cli
# parameter. Therefore, the OSD with desired OSD ID and UUID must
# exist before puppet ceph module executes ceph-disk prepare.

set -x

osd_id=<%= @osd_id %>
osd_uuid=<%= @osd_uuid %>

# Ignore if Ceph is down, this case should only happen on DOR
timeout 10 ceph -s
if [ $? -ne 0 ]; then
    exit 0
fi

# Check if OSD exists and has the correct UUID
osds=( $(ceph osd ls) )
if [[ " ${osds[@]} " =~ " ${osd_id} " ]]; then
    # Get UUID, this is slower than osd ls as it also lists PGs with problems
    # but is the only way to get the uuid of an OSD.
    found_uuid=$(ceph osd dump | grep "^osd.${osd_id} " | awk '{print $NF}')
    if [ "${found_uuid}" != "${osd_uuid}" ]; then
        # At B&R ceph's crushmap is restored but, although OSDs are properly
        # allocated to their hosts in the tree, crushmap does not store
        # OSD UUIDs. Therefore, w/o osd_id and uuid match, when the OSD is
        # prepared there is a chance that ceph-disk will create a new OSD
        # that will no longer match the osd id in sysinv db. So, we have
        # to remove OSDs that don't match UUIDs and recreate them with
        # expected OSD ID and UUID so that ceph-disk does not get confused.
        ceph osd rm ${osd_id}
        RET=$?
        if [ $RET -ne 0 ]; then
            echo "Error removing osd ${osd_id}, exit code: ${RET}"
            exit $RET
        fi
    else
        # OSD exists and has the correct uuid
        exit 0
    fi
fi

# Create the OSD with desired id and uuid
ceph osd create ${osd_uuid} ${osd_id}
RET=$?
if [ $RET -ne 0 ]; then
    echo "Error creating osd ${osd_id}, exit code: ${RET}"
    exit $RET
fi
set +x
